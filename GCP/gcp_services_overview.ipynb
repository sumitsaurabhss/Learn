{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36681f0e",
   "metadata": {},
   "source": [
    "## Compute Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44c4f5",
   "metadata": {},
   "source": [
    "### Compute Engine\n",
    "- Virtual Machines\n",
    "- Linux/Windows server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f864da2",
   "metadata": {},
   "source": [
    "### Kubernetes Engine\n",
    "- Cluster of Servers\n",
    "- Cluster of Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6addc772",
   "metadata": {},
   "source": [
    "### Cloud Run\n",
    "- Serverless service for containerized applications that are stateless\n",
    "- it can deploy a service or a job\n",
    "- a service continues to run (is available) e.g., an API call that provides weather data\n",
    "- a job runs on intervals like, every night.\n",
    "- every Cloud Run Service is provided with an HTTPS endpoint on a unique subdomain of the `.run.app` domain.\n",
    "- Completely autoscalable\n",
    "- built-in traffic management\n",
    "\n",
    "Cloud Run is focused on container-based development, allowing you to run applications serving multiple endpoints on a larger scale and with fewer architectural restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98806b",
   "metadata": {},
   "source": [
    "### Cloud Functions\n",
    "- Event driven serverless functions\n",
    "- It uses Trigger for this like, a Pub/Sub service. Pub/Sub is a messaging service that enables exchange of information between services that are working independently. When a message is written to a Pub/Sub topic, actions can be taken by Cloud Functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda69ca6",
   "metadata": {},
   "source": [
    "## Storage Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fad5e",
   "metadata": {},
   "source": [
    "### Cloud Storage - Object storage\n",
    "Serverless and managed service with low cost and high scalability\n",
    "\n",
    "Use cases\n",
    "- Cloud native applications\n",
    "- Analytics and ML\n",
    "- Backup and archive\n",
    "- Media\n",
    "\n",
    "Objects in Cloud Storage \n",
    "- Bucket: An abstraction for organizing folders and objects or files. A bucket is a top level point of entry into object storage for the data that we want to organize as a unit. \n",
    "\n",
    "Commands\n",
    "- list files: `gsutil ls` ~ `gcloud storage ls`\n",
    "- `gcloud storage` is more optimized for larger data.\n",
    "- copy files: `gsutil cp <'gs://path/to/file'> <path/to/dir>`\n",
    "- delete file: `gsutil rm`\n",
    "\n",
    "Storage Classes\n",
    "- Standard\n",
    "- Nearline\n",
    "- Coldline\n",
    "- Archive  \n",
    "Storage class can be specified by creating a `Rule` under `Lifecycle` menu. It is unidirectional and can be lowered only but not raised.\n",
    "\n",
    "Protection menu\n",
    "- Object Versioning\n",
    "- Retention Policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46130ce9",
   "metadata": {},
   "source": [
    "### Persistent Disks - Block storage\n",
    "Used with VMs and containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38bf51",
   "metadata": {},
   "source": [
    "### Database Storage\n",
    "- Relational databases: Cloud SQL, Cloud Spanner\n",
    "- NoSQL databases: Cloud Firestore, BigTable\n",
    "- Analytical database: BigQuery\n",
    "\n",
    "**Cloud SQL**\n",
    "- MySQL\n",
    "- PostgrSQL\n",
    "- SQl Server\n",
    "\n",
    "**Cloud Firestore**: serverless Document database\n",
    "- Collection - analogous to tables\n",
    "- Documents - analogous to rows\n",
    "- Fields - analogous to columns or attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93575efa",
   "metadata": {},
   "source": [
    "## Data Services\n",
    "- BigQuery - Warehouse with BI and analytics (ad-hoc like querying) and ML service\n",
    "- Dataflow: managed service based on Apache Beam for Batch and Stream processing of data\n",
    "- Dataproc: managed service, supports both Apache Hadoop and Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0a8b5",
   "metadata": {},
   "source": [
    "## Most widely used cammands\n",
    "- `gcloud`: for most google cloud services\n",
    "- `bq`: specific for BigQuery\n",
    "- `kubectl`: Kubernetes Clusters\n",
    "- `gsutil`: Google cloud storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc99dfb",
   "metadata": {},
   "source": [
    "## Google Kubernetes Engine\n",
    "- managed service to deploy and use kubernetes clusters\n",
    "- allows to orchestrate a large number of containers that work together.\n",
    "- allows to run stateful applications in containers.\n",
    "\n",
    "Key Concepts\n",
    "- Container: lightweight and isolated enironment to package an application with configuration needed to run it.\n",
    "- Pod: In distributed applications that use containers, containers often work closely together and have very similar lifecycles. So those sets of highly integrated, tightly coupled containers are treated as a single unit. This abstraction in Kebernetes is called a Pod. A pod may contain one or more containers.\n",
    "- Node: Pods are deployed to a resource known as a Node. Nodes can run on virtual machines or physical servers. A node can have multiple pods running on them.\n",
    "- Cluster: A set of nodes that run pods are known as a Cluster.\n",
    "\n",
    "A Kubernetes cluster allows to manage multiple nodes or multiple servers as a single logical unit. This is advantageous in designing systems that are highly available and highly scalable.\n",
    "\n",
    "Nodes can be configured into a Node Pool. A node pool is a set of nodes that are similarly configured and often used to configure certain kinds of nodes and then ensuring that certain pods run on those nodes. E.g, GPUs for ML tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bbc76e",
   "metadata": {},
   "source": [
    "### Cluster Modes\n",
    "- Autopilot: Google cloud manages the cluster and size, and add nodes as needed. It does not allocate any infrastructure until it is given a workload.\n",
    "\n",
    "- Standard: Cluster is managed by the user. Some infrastructure is allocated when it is created. It allows to configure node pools.\n",
    "\n",
    "When we create nodes or node pools, VMs are created on compute engine. These VMs are managed by GKE clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42baea5b",
   "metadata": {},
   "source": [
    "### Monitor Kubernetes cluster states\n",
    "Observability menu shows metrics and logs.\n",
    "- cyan - info\n",
    "- yellow - warning\n",
    "- red - eror"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f937e",
   "metadata": {},
   "source": [
    "## BigQuery\n",
    "Managed serverless data warehousing and analytics platform which is constantly being expanded. Now it includes support for ML using SQL.\n",
    "\n",
    "- Serverless data warehouse\n",
    "    - Petabyte scale\n",
    "    - Uses SQL but not a relational database\n",
    "    - Analytical database\n",
    "\n",
    "- Other features\n",
    "    - BigQuery ML for machine learning\n",
    "    - BigQuery BI Engine for high performance ad hoc querying\n",
    "    - BigQuery GIS for geographic information systems\n",
    "    - BigQuery Omni, a version of BigQuery that can run in other clouds\n",
    "\n",
    "**Ways to Query data in BigQuery**\n",
    "- SQL GUI\n",
    "- bq command\n",
    "- Storage API (to pull data into your platform or framework)\n",
    "    - Spark\n",
    "    - Tensorflow\n",
    "    - Dataflow\n",
    "    - Pandas\n",
    "    - Scikit-learn\n",
    "\n",
    "BigQuery uses this convention when it's naming tables (for querying using SQL). It starts with the project name and then follow that by the dataset name and then finally comes the table. It uses a 'dot' in between.\n",
    "\n",
    "Create dataset using table with a specific view:\n",
    "1. Create a dataset by clicking three stacked dots.\n",
    "2. Use following code in SQL GUI:\n",
    "```sql\n",
    "CREATE VIEW dataset_name.view_name AS\n",
    "SELECT\n",
    "    column_1, column_2, column_3\n",
    "FROM\n",
    "    project_id.dataset_name.table_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a347e5a",
   "metadata": {},
   "source": [
    "### BigQuery ML Model Types\n",
    "- Logistic Regression\n",
    "\n",
    "- Kmeans\n",
    "- PCA\n",
    "\n",
    "- AutoML Classifier\n",
    "- Boosted Tree Classifier\n",
    "- Random Forest Classifier\n",
    "\n",
    "- ARIMA Plus  \n",
    "\n",
    "and more ...\n",
    "\n",
    "**Create and use a ML model**  \n",
    "\n",
    "- BigQuery has extended SQL to include a new statement called `CREATE MODEL`\n",
    "\n",
    "```sql\n",
    "CREATE MODEL gce_bqml.gce_model_1\n",
    "OPTIONS(model_type='logistic_reg') AS\n",
    "SELECT\n",
    "    IF(totals.transactions IS NULL, 0, 1) AS label,\n",
    "    IFNULL(device.operatingSystem, \"\") AS os,\n",
    "    device.isMobile AS is_mobile,\n",
    "    IFNULL(geoNetwork.country, \"\") AS country,\n",
    "    IFNULL(totals.pageviews, 0) AS pageviews\n",
    "FROM\n",
    "    bigquery-public-data.google_analytics_sample.ga_sessions_*      \n",
    "WHERE\n",
    "    _TABLE_SUFFIX BETWEEN '20160801' AND '20170630'\n",
    "```\n",
    "\n",
    "> \\* is a wild card which allows to query from several tables that have this pattern which is restricted by the `WHERE` clause.\n",
    "\n",
    "\n",
    "- It has also provided with `ML` a library of functions related to ML like `EVALUATE`.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL gce_bqml.gce_model_1, (\n",
    "SELECT\n",
    "    IF(totals.transactions IS NULL, 0, 1) AS label,\n",
    "    IFNULL(device.operatingSystem, \"\") AS os,\n",
    "    device.isMobile AS is_mobile,\n",
    "    IFNULL(geoNetwork.country, \"\") AS country,\n",
    "    IFNULL(totals.pageviews, 0) AS pageviews\n",
    "FROM\n",
    "    bigquery-public-data.google_analytics_sample.ga_sessions_*      \n",
    "WHERE\n",
    "    _TABLE_SUFFIX BETWEEN '20170701' AND '20170801'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a199985",
   "metadata": {},
   "source": [
    "## IAM\n",
    "**Identity Types**  \n",
    "- Google account: A gmail account associated with google cloud\n",
    "- Google group: A group of accounts that need same level of privileges are added to a group and a role or permissions are given to the group\n",
    "- Google Workspace or Cloud Identity: Identity created by an organization using Cloud Identity service\n",
    "- Service account: to give roles or permissions to a service to do certain things without the need of a username and password\n",
    "\n",
    "**Access Management**  \n",
    "- Identities granted access to resources\n",
    "- Permission specify allowed operations\n",
    "- Permissions are assigned to roles\n",
    "- Roles are assigned to identities\n",
    "\n",
    "**3 Kind of Roles**  \n",
    "- Predefined\n",
    "- Custom\n",
    "- Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb0663",
   "metadata": {},
   "source": [
    "- Principle: A term for an identity for a person or a service account that can do certain things. In the google cloud, email addresses (like, 837782-compute@developer.gserviceaccount.com) are used a way to identify them.\n",
    "\n",
    "- Naming convention for Permission: service_name.resource_name.operation_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dfc48",
   "metadata": {},
   "source": [
    "## Networking\n",
    "**VPC (Virtual Private Cloud)**  \n",
    "A partioned off section of the Google cloud infrastructure that is managed by users. Networking in google cloud is thought in terms of virtual private clouds.\n",
    "\n",
    "- Flow logs: Networking logs, helpful for debugging networking issues, can get pretty big, pretty fast and can incur huge cost on storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d564d8",
   "metadata": {},
   "source": [
    "Terms\n",
    "- Network\n",
    "- Subnet\n",
    "- CIDR (Classless Internet Routing Domains): Specify internal addresses that are private to that subnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cac4a3",
   "metadata": {},
   "source": [
    "## Artifact and Container Registry\n",
    "- A single registry for storing and managing packages and container images\n",
    "    - Integrates Artifact Registry with Google Cloud CI/CD services\n",
    "    - Deploy artifacts to Google Cloud compute resources\n",
    "\n",
    "- Protect software supply chain\n",
    "    - Scan for container vulnerabalities\n",
    "    - Enforce deployment policies with Binary Authorization\n",
    "\n",
    "- Create multiple regional repositories within a project\n",
    "\n",
    "> A registry is a location to store and manage packages, images and libraries.\n",
    "\n",
    "Artifact Registry integrates the components it keeps with different continuous integration and continuous deployment services that Google Cloud has, like Cloud Build. It allows to have a central place to perform operations like, scan for vulnerabilities or define ploicies for additional security controls, on container images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a97ede",
   "metadata": {},
   "source": [
    "## Cloud Build Repositories\n",
    "- Create connnections to source code repositories\n",
    "    - GitHub\n",
    "    - GitHub Enterprise\n",
    "    - GitLab Enterprise Edition\n",
    "    - Bitbucket Server\n",
    "    - Bitbucket Data Center\n",
    "\n",
    "- Create connections to source code repositories\n",
    "    - 1st Generation - manual, PubSub, Webhook triggers\n",
    "    - 2nd Generation - Terraform integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39d8ab",
   "metadata": {},
   "source": [
    "> Artifact Registry is designed to manage objects or components for an application. And then Cloud Build is used for assembling those components together and building deployable images that can run in Cloud Run or Kebernetes Engine."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
