{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6436c6-91ba-41ab-ac42-f99da107defb",
   "metadata": {},
   "source": [
    "# Generative AI Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df156aee-a205-418c-ad3a-65953eadd52e",
   "metadata": {},
   "source": [
    "## Challenges in Generative AI\n",
    "Generative AI presents exciting opportunities but also involves some challenges that need thoughtful consideration. While these technologies show great promise in creativity and efficiency, it's important to address issues such as misleading information, job displacement, the originality of art, and environmental impacts.\n",
    "\n",
    "Ethical Implications: The potential for creating deepfakes that can deceive people and the issues surrounding originality in art and design.\n",
    "\n",
    "Misinformation Campaigns: Generative AI can be misused to produce fake news articles, videos, and images, which can spread misinformation at an unprecedented rate.\n",
    "\n",
    "Job Displacement: As generative AI systems become more advanced, there is a risk of job automation, particularly for roles involving repetitive tasks, leading to income inequality and societal challenges.\n",
    "\n",
    "Originality and Copyright Issues: The rise of AI-generated art and designs raises questions about the originality of these creations and the challenges artists face in proving the uniqueness of their work.\n",
    "\n",
    "Environmental Impact: Training large-scale generative AI models requires significant computational power, leading to concerns about their carbon footprint and overall environmental impact.\n",
    "\n",
    "Responsibility and Ethical Use: The video emphasizes the need for responsible and ethical use of generative AI technologies, advocating for a balance between harnessing their potential and addressing the challenges they present.\n",
    "\n",
    "Deepfakes: Highly realistic fake videos or images created by AI, which can make it seem like people are saying or doing things they never actually did.\n",
    "\n",
    "Automation: The use of technology to perform tasks without human intervention, which can increase efficiency but also may replace jobs done by people.\n",
    "\n",
    "Copyright Issues: Legal problems that arise when someone uses work without permission, potentially impacting the original creator's rights.\n",
    "\n",
    "Carbon Footprint: The total amount of greenhouse gases produced directly or indirectly by activities or entities, like running large-scale AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d43941-ab83-49ed-b605-1a2ecd333939",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f10f3c93-6f15-4ad5-ae9b-05bc356a35df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3880cf-fa1a-49f9-af8f-e625415050a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e73095b7-e3aa-4674-a0c3-75925efbec5e",
   "metadata": {},
   "source": [
    "# Foundation Model\n",
    "A foundation model is a type of AI model that is trained on a vast amount of data at scale, allowing it to perform a wide range of tasks with minimal additional training. These models serve as a base for various applications. They excel at learning from extensive datasets, enabling them to generalize and perform well on tasks they weren't explicitly trained for.\n",
    "- Trained on vast datasets.\n",
    "- Designed to generalize across many tasks, allowing them to perform well on examples they have never seen before.\n",
    "- Require significant computational resources due to their size and complexity.\n",
    "- Examples include models like GPT from OpenAI, Bard from Google, and DALL-E.\n",
    "\n",
    "Generalize: The ability of a model to apply what it has learned from its training data to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fa68f-4273-4afd-aed6-5eaae3f65279",
   "metadata": {},
   "source": [
    "## Traditional Models:\n",
    "- Typically trained on smaller, task-specific datasets.\n",
    "- Developed from scratch based on meticulously curated data, making them task-specific and domain-specific.\n",
    "- Generally smaller in size and require less computational power.\n",
    "- Examples include linear regression, decision trees, and convolutional neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb6d14-3818-4424-8479-0ac629eda751",
   "metadata": {},
   "source": [
    "### Key Differences:\n",
    "\n",
    "Foundation models are versatile and can adapt to various tasks, while traditional models are specialized and limited to specific applications.\n",
    "The emergence of foundation models represents a significant shift in AI, focusing on large-scale training and broad applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bbe2a-60bf-4dbf-8867-0097b5f0c717",
   "metadata": {},
   "source": [
    "## Transformer Architecture\n",
    "The transformer architecture has revolutionized how machines handle sequential data, allowing for the training of large models efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd84c05-dfc5-42bb-bed5-7670fe4e3957",
   "metadata": {},
   "source": [
    "### Self-attention mechanism\n",
    "The self-attention mechanism in a transformer is a process where each element in a sequence computes its representation by attending to and weighing the importance of all elements in the sequence, allowing the model to capture complex relationships and dependencies. This is particularly useful in tasks like language modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c561f7-a828-49f9-82aa-df7cbaf14c9f",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "Why they matter?\n",
    "Benchmarks matter because they are the standards that help us measure and accelerate progress in AI. They offer a common ground for comparing different AI models and encouraging innovation, providing important stepping stones on the path to more advanced AI technologies.\n",
    "\n",
    "Importance of Benchmark Datasets: Benchmark datasets serve as standardized testbeds for algorithms, providing clear, objective, and quantifiable metrics for evaluation.\n",
    "\n",
    "Benefits of Benchmark Datasets:\n",
    "Comparability: They allow for direct comparison of different algorithms and models.  \n",
    "Reproducibility: They create a shared foundation for reproducing and verifying results, crucial for scientific progress.  \n",
    "Focus: They concentrate research efforts on specific problems, leading to innovation.  \n",
    "Democratization: Open access to high-quality datasets levels the playing field for researchers worldwide.  \n",
    "Acceleration of Progress: As models surpass benchmarks, datasets evolve to present new challenges, driving further advancements in AI.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38c2dc-03ee-4420-a6af-56b1bf5e512c",
   "metadata": {},
   "source": [
    "### GLUE - General Language Understanding Evaluation\n",
    "The GLUE benchmark is designed to assess the capabilities of AI models across a variety of linguistic tasks, serving as a litmus test for their understanding of human language. They serve as an essential tool to assess an AI's grasp of human language, covering diverse tasks, from grammar checking to complex sentence relationship analysis. By putting AI models through these varied linguistic challenges, we can gauge their readiness for real-world tasks and uncover any potential weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08a8ba-8295-4595-8508-4e189b5ab288",
   "metadata": {},
   "source": [
    "#### The GLUE Tasks / Benchmarks\n",
    "##### CoLA (Corpus of Linguistic Acceptability) - Grammatical Acceptibility\n",
    "    Measures the ability to determine if an English sentence is linguistically acceptable. \n",
    "\n",
    "##### SST-2 (Stanford Sentiment Treebank) - Sentiment Analysis\n",
    "    Consists of sentences from movie reviews and human annotations about their sentiment. Analyzes sentiment in movie reviews.  \n",
    "\n",
    "##### MRPC (Microsoft Research Paraphrase Corpus) - Paraphrase Identification\n",
    "    Focuses on identifying whether two sentences are paraphrases of each other.  \n",
    "\n",
    "##### STS-B (Semantic Textual Similarity Benchmark) - Semantic Textual Similarity\n",
    "    Involves determining how similar two sentences are in terms of semantic content.  \n",
    "\n",
    "##### QQP (Quora Question Pairs) - Question Pairs Equivalence\n",
    "    Aims to identify whether two questions asked on Quora are semantically equivalent. Evaluates semantic equivalence of questions. \n",
    "\n",
    "##### MNLI (Multi-Genre Natural Language Inference) - Natural Language Inference\n",
    "    Consists of sentence pairs labeled for textual entailment across multiple genres of text. Assesses the relationship between sentence pairs.  \n",
    "\n",
    "##### QNLI (Question Natural Language Inference) - Question Answering Inference\n",
    "    Involves determining whether the content of a paragraph or a context sentence contains the answer to a question.\n",
    "\n",
    "##### RTE (Recognizing Textual Entailment) - Textual Entailment Recognition\n",
    "    Requires understanding whether one sentence entails another.\n",
    "\n",
    "###### WNLI (Winograd Natural Language Inference) - Pronoun Disambiguation\n",
    "    Tests a system's reading comprehension by having it determine the correct referent of a pronoun in a sentence, where understanding depends on contextual information provided by specific words or phrases. Tests reading comprehension by resolving pronouns in context.  \n",
    "\n",
    "\n",
    "Semantic Equivalence: When different phrases or sentences convey the same meaning or idea.\n",
    "\n",
    "Textual Entailment: The relationship between text fragments where one fragment follows logically from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11830187-0072-4b0c-a64f-2ddcb1ea7ba3",
   "metadata": {},
   "source": [
    "#### Importance of Evaluation \n",
    "The GLUE benchmark allows researchers to compare the performance of different models on standardized tasks, facilitating advancements in natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9dd8e5-7453-4c4c-a7de-711fa1dcf9cc",
   "metadata": {},
   "source": [
    "### SuperGlue\n",
    "SuperGlue is designed as a successor to the original GLUE benchmark. It's a more advanced benchmark aimed at presenting even more challenging language understanding tasks for AI models. Created to push the boundaries of what AI can understand and process in natural language, SuperGlue emerged as models began to achieve human parity on the GLUE benchmark. It also features a public leaderboard, facilitating the direct comparison of models and enabling the tracking of progress over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f28b8-df58-4313-90d0-2b3b40ac2e12",
   "metadata": {},
   "source": [
    "#### SuperGlue Tasks / Benchmarks\n",
    "##### BoolQ (Boolean Questions)\n",
    "Involves answering a yes/no question based on a short passage.\n",
    "\n",
    "##### CB (Commitment Bank)\n",
    "    Tests understanding of entailment and contradiction in a three-sentence format.\n",
    "\n",
    "##### COPA (Choice of Plausible Alternatives)\n",
    "    Measures causal reasoning by asking for the cause/effect of a given sentence.\n",
    "\n",
    "##### MultiRC (Multi-Sentence Reading Comprehension)\n",
    "    Involves answering questions about a paragraph where each question may have multiple correct answers.\n",
    "\n",
    "##### ReCoRD (Reading Comprehension with Common Senese Reasoning)\n",
    "    Requires selecting the correct named entity from a passage to fill in the blank of a question.\n",
    "\n",
    "##### RTE (Recognizing Textual Entailment)\n",
    "    Involves identifying whether a sentence entails, contradicts, or is neutral towards another sentence.\n",
    "\n",
    "##### WiC (Words in Context)\n",
    "    Tests understanding of word sense disambiguation in different contexts.\n",
    "\n",
    "##### WSC (Winograd Schema Challenge)\n",
    "    Focuses on resolving coreference resolution within a sentence, often requiring commonsense reasoning.\n",
    "\n",
    "##### AX-b (Broad Coverage Diagnostics)\n",
    "    A diagnostic set to evaluate model performance on a broad range of linguistic phenomena.\n",
    "    \n",
    "##### AX-g (Winogender Schema Diagnostics)\n",
    "    Tests for the presence of gender bias in automated coreference resolution systems.\n",
    "\n",
    "\n",
    "Coreference Resolution: This is figuring out when different words or phrases in a text, like the pronoun she and the president, refer to the same person or thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ecdf16-7c97-4ca3-b8b8-e09de7578967",
   "metadata": {},
   "source": [
    "## Data used for Training LLMs\n",
    "Generative AI, specifically Large Language Models (LLMs), rely on a rich mosaic of data sources to fine-tune their linguistic skills. These sources include web content, academic writings, literary works, and multilingual texts, among others. By engaging with a variety of data types, such as scientific papers, social media posts, legal documents, and even conversational dialogues, LLMs become adept at comprehending and generating language across many contexts, enhancing their ability to provide relevant and accurate information.\n",
    "\n",
    "### Diverse Data Sources\n",
    "- Websites: Content from various online sources, including articles and blogs, helps models learn both formal and informal language.\n",
    "- Scientific Papers: Academic texts provide technical language and complex concepts, which are useful for expert-level queries.\n",
    "- Encyclopedias: Factual entries give models a basis for general knowledge across many topics.\n",
    "- Books and Literature: Classic and modern literature enriches the model's vocabulary and understanding of complex sentence structures.\n",
    "- Conversational Data: Transcripts from dialogues and chatbots help models grasp nuances in dialogue and colloquial speech.\n",
    "- Social Media Posts: This data helps models understand current linguistic trends and informal communication styles.\n",
    "- Legal Documents: These texts train models to comprehend formal language and complex structures.\n",
    "- Multilingual Texts: Including texts in various languages helps models understand and generate language across different linguistic contexts.\n",
    "\n",
    "\n",
    "Preprocessing: This is the process of preparing and cleaning data to ensure quality before it is used to train a machine learning model. It might involve removing errors, irrelevant information, or anonymizing information or formatting the data in a way that the model can easily learn from it.\n",
    "\n",
    "Fine-tuning: After a model has been pre-trained on a large dataset, fine-tuning is an additional training step where the model is further refined with specific data to improve its performance on a particular type of task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ce3db-e1d0-42dd-bc6a-4817f0326252",
   "metadata": {},
   "source": [
    "### Pre-training Datasets\n",
    "- CommonCrawl: [https://commoncrawl.org/](https://commoncrawl.org/)\n",
    "- Github: [https://www.githubarchive.org/](https://www.githubarchive.org/)\n",
    "- Wikipedia: [Wikimedia Downloads](https://dumps.wikimedia.org/)\n",
    "- Gutenberg Project: [https://www.gutenberg.org/](https://www.gutenberg.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c8cf3-7f74-4889-acd5-8e2202cadc65",
   "metadata": {},
   "source": [
    "### Data Scale and Volume\n",
    "The scale of data for Large Language Models (LLMs) is tremendously vast, involving datasets that could equate to millions of books. The sheer size is pivotal for the model's understanding and mastery of language through exposure to diverse words and structures.\n",
    "\n",
    "Common Crawl: An open repository of web crawl data. Essentially, it is a large collection of content from the internet that is gathered by automatically scraping the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082e15f-0b45-45f7-992e-5b6e40a6b86e",
   "metadata": {},
   "source": [
    "### Biases in Training Data\n",
    "Biases in training data deeply influence the outcomes of AI models, reflecting societal issues that require attention. Ways to approach this challenge include promoting diversity in development teams, seeking diverse data sources, and ensuring continued vigilance through bias detection and model monitoring.\n",
    "\n",
    "#### Types of Bias\n",
    "##### Selection Bias - Biased data selection\n",
    "    When the data used to train an AI model does not accurately represent the whole population or situation by virtue of the selection process leading to a skewed result, e.g. those choosing the data will tend to choose dataset their are aware of.\n",
    "    \n",
    "##### Historical Bias - Caused by historical prejudices in data\n",
    "    Prejudices and societal inequalities of the past that are reflected in the data, influencing the AI in a way that perpetuates these outdated beliefs.\n",
    "    \n",
    "##### Confirmation Bias - caused by data with pre-existing beliefs\n",
    "    Arises when data is selected to confirm pre-existing beliefs, further skewing the model's understanding.\n",
    "\n",
    "#### Effects of Biased Data\n",
    "##### Discriminatory Outcomes\n",
    "    Unfair results produced by AI that disadvantage certain groups, often due to biases in the training data or malicious actors, such as biased hiring practices or loan approvals.\n",
    "    \n",
    "##### Echo Chambers\n",
    "    Situations where biased AI reinforces and amplifies existing biases, leading to a narrow and distorted sphere of information. This can create feedback loops that reinforce existing biases, limiting diverse perspectives.\n",
    "\n",
    "##### Misrepresentation\n",
    "    Certain groups may be underrepresented or misrepresented in the outputs of AI models.\n",
    "\n",
    "#### Mitigating Bias\n",
    "##### Organizational Diversity\n",
    "    Ensuring that the teams involved are diverse\n",
    "    - Fair models = fair teams, companies, and society\n",
    "\n",
    "##### Diverse Data Collection\n",
    "    Actively seeking out diverse data sources\n",
    "\n",
    "##### Bias Detection and Correction - employing algorithms and human oversight\n",
    "    Processes and algorithms designed to identify and remove biases from data before it's used to train AI models.\n",
    "\n",
    "##### Transparency and Accountability - being transparent about sources and nature of training data \n",
    "    Openness about how AI models are trained and the nature of their data, ensuring that developers are answerable for their AI's performance and impact.\n",
    "\n",
    "##### Continuous Monitoring\n",
    "    Regularly testing and updating the models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aedb91-d548-4bd1-a8f0-dd2b80409359",
   "metadata": {},
   "source": [
    "## Disinformation and Misinformation\n",
    "Disinformation refers to the deliberate creation and dissemination of false information with the intent to deceive.\n",
    "\n",
    "Misinformation, on the other hand, is false information spread without the intent to mislead, often due to carelessness or negligence.\n",
    "\n",
    "Synthetic Voices: These are computer-generated voices that are often indistinguishable from real human voices. AI models have been trained on samples of speech to produce these realistic voice outputs.\n",
    "\n",
    "Content Provenance Tools: Tools designed to track the origin and history of digital content. They help verify the authenticity of the content by providing information about its creation, modification, and distribution history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a0314-a46f-43e9-b54b-458399cc64d8",
   "metadata": {},
   "source": [
    "## Environmental and Human Impacts of Foundational Models\n",
    "### Environmental Impacts\n",
    "Energy Consumption: Training foundation models requires substantial computational power, leading to high energy consumption. The carbon footprint of training a single AI model can be comparable to the lifetime emissions of several cars.\n",
    "\n",
    "Resource Use: The production of hardware necessary for training, such as GPUs and TPUs, involves resource extraction and manufacturing processes that have environmental costs, contributing to electronic waste and resource depletion.\n",
    "\n",
    "Electronic Waste: The rapid development of AI technology leads to a proliferation of hardware that quickly becomes obsolete, resulting in increasing amounts of electronic waste.\n",
    "\n",
    "### Human Impacts\n",
    "Economic Disruption: AI can automate tasks traditionally performed by humans, potentially displacing workers in various sectors. While it may create new jobs, this transition can be challenging for those affected.\n",
    "\n",
    "Bias and Fairness: Foundation models can inherit and amplify biases present in their training data, leading to unfair outcomes for certain individuals or groups, particularly marginalized communities.\n",
    "\n",
    "Privacy Concerns: The vast amounts of data used to train these models may include sensitive personal information, raising issues about data protection and privacy.\n",
    "\n",
    "Misinformation and Security Risks: The ability of foundation models to generate persuasive text can be exploited for misinformation, while their advanced capabilities pose new security challenges.\n",
    "\n",
    "Existential Threats: The potential misuse of AI, such as in autonomous weapons, raises concerns about existential threats to humanity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4bc13b-5d35-460d-8aa7-c50b7d7a8eca",
   "metadata": {},
   "source": [
    "# Adaptation\n",
    "Adaptation refers to the process of customizing pre-trained foundation models to better suit specific applications or to incorporate up-to-date information. To leverage the full potential of foundation models for particular tasks or domains, it is often necessary to fine-tune or adapt them. This enhances their performance and ensures that outcomes align with specific organizational requirements or privacy constraints.  \n",
    "Adapting foundation models is essential due to their limitations in specific areas despite their extensive training on large datasets. Although they excel at many tasks, these models can sometimes misconstrue questions or lack up-to-date information, which highlights the need for fine-tuning. By addressing these weaknesses through additional training or other techniques, the performance of foundation models can be significantly improved.\n",
    "\n",
    "## Methods of Adaptation:\n",
    "\n",
    "### Fine-tuning\n",
    "This is a technique in machine learning where an already trained model is further trained (or tuned) on a new, typically smaller, dataset for better performance on a specific task. Here, it involves taking a pre-trained model and training it again with new data to improve its performance on specialized tasks.\n",
    "\n",
    "\n",
    "### Domain-Specific Training\n",
    "Adapting models for specific industries, such as banking or healthcare, to ensure they can handle relevant queries and data structures.\n",
    "\n",
    "\n",
    "\n",
    "General Instruction-Based Adaptation: Using curated datasets to fine-tune models for better performance on unforeseen tasks, such as translation or summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291704e-ebce-48cb-9ac9-c8aa199f6be6",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation\n",
    "Retrieval-Augmented Generation (RAG) is a technique that improves the performance of generative models by incorporating relevant information retrieved from external databases or documents. It is a powerful approach for keeping Generative AI models informed with the most recent data, particularly when dealing with domain-specific questions. It cleverly combines the comprehensive understanding capacity of a large language model (LLM) with the most up-to-date information pulled from a database of relevant text snippets. The beauty of this system is in its ability to ensure that responses remain accurate and reflective of the latest developments.\n",
    "\n",
    "### Process Overview\n",
    "- Query Generation: The process begins with a user query or prompt that requires a response.\n",
    "- Information Retrieval: The system retrieves relevant snippets or documents from a knowledge base or database that may contain the answer to the query.\n",
    "- Response Generation: The retrieved information is then combined with the original query and fed into a generative model (like a large language model) to produce a coherent and contextually relevant response.\n",
    "\n",
    "Benefits of RAG:\n",
    "- Access to Up-to-Date Information: RAG allows models to access the latest data, making them more accurate and relevant, especially for time-sensitive queries.\n",
    "- Improved Accuracy: By grounding responses in real data, RAG reduces the likelihood of generating incorrect or fabricated information.\n",
    "\n",
    "### Applications\n",
    "RAG can be applied in various domains, such as customer support, where accurate and contextually relevant answers are crucial, or in research, where access to specific documents can enhance the quality of generated summaries.\n",
    "\n",
    "\n",
    "Semantic-embedding: A representation of text in a high-dimensional space where distances between points correspond to semantic similarity. Phrases with similar meanings are closer together.\n",
    "\n",
    "Cosine similarity: A metric used to measure how similar two vectors are, typically used in the context of semantic embeddings to assess similarity of meanings.\n",
    "\n",
    "Vector databases: Specialized databases designed to store and handle vector data, often employed for facilitating fast and efficient similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ba0d0-6cb7-4621-bf60-b9bcdf18f4bb",
   "metadata": {},
   "source": [
    "## Prompt Design Techniques\n",
    "Prompt Design Techniques are innovative strategies for tailoring AI foundation models to specific tasks, fostering better performance in various domains. These methods enable us to guide the AI's output by carefully constructing the prompts we provide, enhancing the model's relevance and efficiency in generating responses.\n",
    "\n",
    "\n",
    "Prompt: In AI, a prompt is an input given to the model to generate a specific response or output.\n",
    "\n",
    "Domain-Specific Task: A task that is specialized or relevant to a particular area of knowledge or industry, often requiring tailored AI responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795a4a1-fccd-480a-b876-0ad917eeb2c2",
   "metadata": {},
   "source": [
    "### Prompt Tuning\n",
    "Prompt tuning is a method used to enhance the performance of generative models by optimizing the input prompts that guide the model's predictions. It allows models to target specific tasks effectively. By crafting prompts, whether through a hands-on approach with hard prompts or through an automated process with soft prompts, we enhance the model's predictive capabilities.\n",
    "\n",
    "#### Types of Prompts:\n",
    "- Hard Prompts: These are manually crafted templates that require human intervention to create. They are specific and can be effective but may require extensive trial and error.\n",
    "- Soft Prompts: A series of tokens or embeddings optimized through deep learning to help guide model predictions, without necessarily making sense to humans. These are learned representations that are optimized through training. They may not be interpretable by humans but can lead to improved model performance.\n",
    "\n",
    "#### Benefits of Prompt Tuning\n",
    "By fine-tuning prompts, models can achieve better accuracy and relevance in their outputs, making them more effective for specific tasks.\n",
    "\n",
    "#### Challenges\n",
    "The process can be time-consuming and may require a deep understanding of both the model and the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48906eb9-f0bb-4e70-8bf7-6336d9cc7564",
   "metadata": {},
   "source": [
    "### One and Few-Shot Prompting\n",
    "One and few-shot prompting represent cutting-edge techniques that enable AI to adapt and perform tasks with minimal instructions. Instead of relying on extensive databases for learning, these methods guide generative AI through just one or a few examples, streamlining the learning process and demonstrating its ability to generalize solutions to new problems. \n",
    "\n",
    "\n",
    "One-shot prompting: Giving an AI model a single example to learn from before it attempts a similar task.\n",
    "\n",
    "Few-shot prompting: Providing an AI model with a small set of examples, such as five or fewer, from which it can learn to generalize and perform tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7eed8-d435-4225-be62-3c49fec4856b",
   "metadata": {},
   "source": [
    "### Zero-Shot Prompting\n",
    "Zero-shot prompting is a remarkable technique where a generative AI model can take on new tasks without the need for specific training examples. This process leverages the AI's extensive pre-existing knowledge gained from learning patterns across vast datasets. It empowers the AI to infer and generalize effectively to provide answers and solutions in contexts that were not expressly covered during its initial training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5fd53-b244-4eca-9e84-5a2c3b71d56d",
   "metadata": {},
   "source": [
    "### In-Context Learning\n",
    "When performing few-shot, one-shot, or zero-shot learning, we can pass information to the model within the prompt in the form of examples, descriptions, or other data. When we rely on a model using information from within the prompt itself instead of relying on what is stored within its own parameters we are using in-context learning.\n",
    "\n",
    "As these AI models grow in size, their ability to absorb and use in-context information significantly improves, showcasing their potential to adapt to various tasks effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec7cb9-346c-47ef-bff6-e59c2eef75be",
   "metadata": {},
   "source": [
    "### Chain-of-Thought Prompting\n",
    "A method of guiding a language model through a step-by-step reasoning process to help it solve complex tasks by explicitly detailing the logic needed to reach a conclusion. It is a vital technique for enhancing the reasoning capabilities of large language models by breaking down complex problems into intermediate steps that lead to a solution. By providing models with a line of reasoning, they can more effectively tackle problems that require more advanced problem-solving processes, enabling them to deduce information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd7fc4-9ef3-4153-a3e8-4db937055bd7",
   "metadata": {},
   "source": [
    "## Using Probing to Train a Classifier\n",
    "Using probing to train a classifier is a powerful approach to tailor generative AI foundation models, like BERT, for specific applications. By adding a modestly-sized neural network, known as a classification head, to a foundation model, one can specialize in particular tasks such as sentiment analysis. This technique involves freezing the original model's parameters and only adjusting the classification head through training with labeled data. Ultimately, this process simplifies adapting sophisticated AI systems to our needs, providing a practical tool for developing efficient and targeted machine learning solutions.\n",
    "\n",
    "Probing: This is a method of examining what information is contained in different parts of a machine learning model.\n",
    "\n",
    "Linear Probing: A simple form of probing that involves attaching a linear classifier to a pre-trained model to adapt it to a new task without modifying the original model.\n",
    "\n",
    "Classification Head: It is the part of a neural network that is tailored to classify input data into defined categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7764c-c5e6-440f-947c-0eda4d47882d",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "This is the process of adjusting a pre-trained model so it performs better on a new, similar task. It is an important phase in enhancing the abilities of generative AI models, making them adept at specific tasks. By introducing additional data to these powerful models, they can be tailored to meet particular requirements, which is invaluable in making AI more effective and efficient. Although this process comes with its challenges, such as the need for significant computational resources and data, the outcome is a more specialized and capable AI system that can bring value to a wide range of applications.\n",
    "\n",
    "Catastrophic Forgetting: This happens when a model learns something new but forgets what it learned before. This can happen due to traditional fine-tuning or fine-tuning many layers based on out-of-distribution dataset. The model may forget what it had originally learned on the pre-training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330de1c-44e6-4113-9c73-c6ddd567fd07",
   "metadata": {},
   "source": [
    "### Parameter-Efficient Fine-Tuning\n",
    "    Parameter-efficient fine-tuning (PEFT) is a method of updating a predefined subset of a model's parameters to tailor it to specific tasks, without the need to modify the entire model, thus saving computational resources. One approach is to freeze the majority of the models parameters and only update a small portion of them, such as the final layer aka head. This is a technique crucial for adapting large language models more efficiently, with the bonus of not requiring heavy computational power. This approach includes various strategies to update only a small set of parameters, thereby maintaining a balance between model adaptability and resource consumption. The techniques ensure that models can be swiftly deployed in different industrial contexts, considering both time constraints and the necessity for scaling operations efficiently.\n",
    "\n",
    "### Low-Rank Adaptation (LoRA)\n",
    "    A technique where a large matrix is approximated using two smaller matrices, greatly reducing the number of parameters that need to be trained during fine-tuning. A layer is focused for fine-tuning and the amount changed for the layer is k/a delta layer. It uses smaller matrices to approximate important changes in a layer, reducing the number of trainable parameters without significant loss of function.\n",
    "\n",
    "### Adapters\n",
    "    Additional model components inserted at various layers; only the parameters of these adapters are trained, not of the entire model.\n",
    "\n",
    "\n",
    "\n",
    "Frozen Parameters: In the context of machine learning, this refers to model parameters that are not changed or updated during the process of training or fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7e972-af25-47b0-8486-4f4b8cf70584",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe34530c-d802-4aab-a291-67b097f96937",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e06b9b-d6d2-48dc-9a3e-d9a8bc666a4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3148bcd-02c6-4d20-8a01-34bdc32f5a8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e9c458f-3cd7-441a-a744-84b9d65ed25b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d74a37d1-65e2-4547-a80d-3dc61d393c88",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
