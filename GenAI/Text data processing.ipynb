{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccec3ab4-0776-4f9b-976d-139175803262",
   "metadata": {},
   "source": [
    "## Document Loading\n",
    "Document loading refers to the process of ingesting text data from various sources. This is the first step in processing knowledge for a RAG system.\n",
    "\n",
    "Common Document Loaders\n",
    "|Source Type\t|Techniques / Tools                                       |\n",
    "|---------------|---------------------------------------------------------|\n",
    "|Plain Text\t    |TextLoader (LangChain), Python’s open() function         |\n",
    "|PDFs\t        |PyMuPDF, pdfplumber, PDFMiner                            |\n",
    "|DOCX\t        |python-docx                                              |\n",
    "|CSV & Excel\t|pandas.read_csv(), openpyxl                              |\n",
    "|Webpages\t    |BeautifulSoup, trafilatura                               |\n",
    "|Databases\t    |SQL queries (sqlite3, SQLAlchemy)                        |\n",
    "|APIs\t        |requests, LangChain APILoader                            |\n",
    "\n",
    "> How to Choose the Right Loader?   \n",
    "    - If you need structured data (CSV, JSON) → Use pandas or csv parser.  \n",
    "    - For large PDFs with complex layouts → Use PyMuPDF (better table handling).  \n",
    "    - If the source is a database → Use SQL queries with SQLAlchemy.  \n",
    "    - If the data is from the web → Use BeautifulSoup or trafilatura.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37affe00-c4df-4a7c-a56e-068cd1853e59",
   "metadata": {},
   "source": [
    "## Document Splitting\n",
    "After loading, large documents need to be split into manageable sections for efficient retrieval.\n",
    "\n",
    "Why Split Documents?\n",
    "- LLMs have a context length limit (e.g., GPT-4 has ~8k–32k tokens).\n",
    "- Splitting helps better semantic retrieval (smaller, focused chunks).\n",
    "- Prevents irrelevant information retrieval in RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92dbadf-28f4-470e-a8bc-0f8e903aa3b0",
   "metadata": {},
   "source": [
    "### Common Splitting Technique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c05e6-ebaf-4cf3-bb82-231d01c035cb",
   "metadata": {},
   "source": [
    "#### Character-based Splitting\n",
    "Splits text by characters, maintaining a fixed chunk size (e.g., every 500 characters).\n",
    "\n",
    "When to use: When documents have continuous text with no clear structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d70fd9-a8fc-47fd-87bd-569896d22dfb",
   "metadata": {},
   "source": [
    "#### Senetnce-based Splitting\n",
    "Uses sentence boundaries to ensure meaningful splits. Often done with nltk or spaCy.  \n",
    "When to use: When document meaning depends on complete sentences (e.g., research papers, news articles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f17742-c5ba-4998-8df5-08f21db16bb5",
   "metadata": {},
   "source": [
    "#### Paragraph-based Splitting\n",
    "Splits at paragraph boundaries, preserving logical divisions.  \n",
    "When to use: When documents have well-defined paragraphs (e.g., blogs, legal texts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c56b2-b148-4e66-b8eb-fa04ff2d3008",
   "metadata": {},
   "source": [
    "#### Token-based Splitting\n",
    "Splits based on a fixed number of tokens (e.g., every 512 tokens using tiktoken).  \n",
    "When to use: When token limits matter (e.g., fitting LLM context windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52301141-1bff-4e37-8bab-01bf87bb545e",
   "metadata": {},
   "source": [
    "#### Semantic Splitting\n",
    "Uses AI models (BERT, LangChain RecursiveCharacterTextSplitter) to split text at logical breaks.\n",
    "When to use: When preserving semantic coherence is crucial (e.g., splitting transcripts, technical documents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73899a7-2c24-4aa4-bf7a-b768d57333f7",
   "metadata": {},
   "source": [
    "> Choosing the Right Splitting Strategy  \n",
    "    - If working with plain text with no structure → Use character-based or token-based splitting.  \n",
    "    - If dealing with structured documents (articles, blogs) → Use sentence- or paragraph-based splitting.  \n",
    "    - If meaning must be preserved across chunks → Use semantic splitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b59f60-3845-4a7e-9ea8-0fc7e0365cfc",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "Chunking refers to structuring and organizing text into meaningful segments for retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe679d-d229-448b-b5ea-f888b5ef4db2",
   "metadata": {},
   "source": [
    "### Chunking Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387180dd-0b4c-4583-a88a-a1e968b958da",
   "metadata": {},
   "source": [
    "#### Fixed-size chunking\n",
    "Splits text into equal-length chunks (e.g., every 500 tokens).  \n",
    "Pros: Simple, fast  \n",
    "Cons: May cut off important context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bead7c2-beca-403d-9e51-1012db733f37",
   "metadata": {},
   "source": [
    "#### Sliding Window Chunking\n",
    "Overlapping chunks (e.g., 512 tokens per chunk, 128 tokens overlap).  \n",
    "Pros: Preserves context between chunks.  \n",
    "Cons: Increases storage & Retrieval overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077f066-dcc8-46a9-9353-2d7127b6b065",
   "metadata": {},
   "source": [
    "#### Recursive Chunking\n",
    "Splits text at logical boundaries (e.g., heading → paragraph → sentence).  \n",
    "Pros: Maintains document structure.  \n",
    "Cons: Needs NLP models to declare boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03318c-40fd-4b05-bc03-0fcdc5c4dbb4",
   "metadata": {},
   "source": [
    "#### Dynamic Chunking\n",
    "Adjusts chunk size based on content (e.g., keeping topic coherence).  \n",
    "Pros: Preserves meaning better.  \n",
    "Cons: Computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e4b4c-9804-40b3-a0ee-ffa1a690ecca",
   "metadata": {},
   "source": [
    "> Choosing the Right Chunking Strategy\n",
    "    - If speed & simplicity matter → Use fixed-size chunking.  \n",
    "    - If context preservation is important → Use sliding window chunking.  \n",
    "    - If documents have structured sections → Use recursive chunking.  \n",
    "    - If you need adaptive retrieval → Use dynamic chunking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa4c7b-0777-4e17-9747-3d983231081b",
   "metadata": {},
   "source": [
    "## Final Decision Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded44e65-4a34-4c8c-b766-a25827f6b4ed",
   "metadata": {},
   "source": [
    "|Scenario\t                                             |Recommended Approach\n",
    "|--------------------------------------------------------|-------------------------------------------------|\n",
    "|Short plain text files (blogs, news articles)\t         |Sentence-based splitting + Fixed-size chunking\n",
    "|Long structured documents (PDFs, books)\t             |Paragraph-based splitting + Recursive chunking\n",
    "|AI chatbots that need context\t                         |Sliding window chunking\n",
    "|Knowledge bases with different formats\t                 |Dynamic chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5248323-56e1-4d59-bdf9-76ac2be59dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
