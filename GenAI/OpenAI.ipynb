{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3902aba9-a586-417c-aae9-2a74bdb5e074",
   "metadata": {},
   "source": [
    "## Text Generation - chat completions endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3266638-72a5-4f56-a0bd-db102ad9b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"OpenAI_API_Key\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\"\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is OpenAI API?\"}]\n",
    ")\n",
    "\n",
    "# response from OpenAI is a ChatCompletion object.\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8bd7a-cc45-413b-a4cb-4d85e1c19ceb",
   "metadata": {},
   "source": [
    "### Generating and Transforming Text\n",
    "- `temperature`: Control randomness [0-2] (default-1)\n",
    "- `max_tokens`: Control maximum length of response, shortening or lengthening it.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeaca3d-a537-4d7d-85cb-01c2bd5bca7f",
   "metadata": {},
   "source": [
    "#### Cost\n",
    "- Usage costs dependent on amount of input and output text\n",
    "    - Models are priced by cost/tokens\n",
    "    - Input and output tokens can be priced differently\n",
    "- Increasing max_tokens increases cost\n",
    "- Scoping feature cost often starts with a rough calculation of cost per time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a236ce-9166-41e8-a943-46318e6b30c9",
   "metadata": {},
   "source": [
    "### Single-turn tasks\n",
    "- Text generation\n",
    "- Text transformation\n",
    "- Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e3771-8c07-439d-879c-e6654f88ebce",
   "metadata": {},
   "source": [
    "### Multi-turn converstions\n",
    "conversations built on previous prompts and responses\n",
    "\n",
    "#### Roles\n",
    "- System: controls assistant's behavior\n",
    "- User: instruct the assistant\n",
    "- Assistant: response to user instruction\n",
    "    - can also be written by the user to provide examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701035f7-a48e-4971-b9e2-2bc65e7a5d8c",
   "metadata": {},
   "source": [
    "## Text moderation - moderations endpoint\n",
    "Text moderation is the process of identifying text that is inappropriate for the context it is being used in.  \n",
    "Traditionally, this moderation was done by-hand, where a team of moderators flagged the content that breached usage rules. Manual moderation is extremely time-consuming and, if multiple moderators are involved, introduces a subjective element that may result in inconsistencies.  \n",
    "More recently this was done by algorithms that detected and flagged content containing particular words. Keyword pattern matching, although much quicker and able to run round-the-clock, can be a clumsy tool that misses some malicious content while accidentally flagging perfectly good content because it doesn't understand nuance or the context of the discussion.\n",
    "\n",
    "To prevent the misuse of their own models, OpenAI have developed moderation models to flag content that breaches their usage policies.\n",
    "- Identify violations of terms or use\n",
    "- Differentiate violation type by category\n",
    "    - Violence\n",
    "    - Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e849f-bb20-4d3c-b329-6f86d1b62818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"OpenAI_API_Key\")\n",
    "\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"I could kill for a hamburger.\"\n",
    ")\n",
    "\n",
    "# dump the response to a dictionary for easy readability\n",
    "print(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd61a3-4604-400f-9e63-ea438acea685",
   "metadata": {},
   "source": [
    "### Interpreting the results\n",
    "- `categories`: `true`/`false` indicator of category violation for different categories\n",
    "- `category_scores`: float values for each category indicating the model's confidence of a violation\n",
    "    - The scores can be between 0 and 1, and although higher values represent higher confidence, they should not be interpreted as probabilities.\n",
    "    - The model uses the rest of the sentence to interpret the context and accurately infer the statement's meaning and use that to moderate the content.\n",
    "    - Determine appropriate thresholds for each use case.\n",
    "- `flagged`: `true`/`false` indicator of overall violation i.e., whether the terms of use have been violated in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6389fa-e78d-4e69-9515-fb573b867099",
   "metadata": {},
   "source": [
    "## OpenAI's Whisper - audio endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4c306-b7f0-493c-a9a5-b3d03ab47da0",
   "metadata": {},
   "source": [
    "### Speech-to-text capabilities - audio.transcriptions endpoint\n",
    "- Transcribe audio\n",
    "- Translate and transcribe audio into English\n",
    "- Supports `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `wav`, and `webm` (25 MB limit)\n",
    "- Meeting transcript\n",
    "\n",
    "Sensitive and confidential audio should not be sent to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70b5d9-2028-4c38-b908-02f2e0f86419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file to read in binary format (typical for non-text files like audio, video and images)\n",
    "audio_file = open(\"path/to/file/meeting_recording.mp3\", \"rb\")\n",
    "\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd82fa-fdd9-4540-a3f0-13a15a900853",
   "metadata": {},
   "source": [
    "### Translation capabilities - audio.translations endpoint\n",
    "- Translate and transcribe audio\n",
    "- Currently limited to English transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3963b7-9289-4545-ae7f-e5f6b347bb3c",
   "metadata": {},
   "source": [
    "### Prompts\n",
    "- Can provide `prompt` to the model (optional)\n",
    "- Improve response quality by:\n",
    "    - providing an example of desired style. Eg. Retaining filler words\n",
    "    - provide additional context about transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea387de-f59a-4d7c-93f5-0ad9e439226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(\"non-english_audio.m4a\", 'rb')\n",
    "prompt = \"The transcript is about AI trends and ChatGPT.\"\n",
    "\n",
    "response = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file, \n",
    "    # prompt=prompt              # optional\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d83bc-1775-42b1-9d7f-552016224812",
   "metadata": {},
   "source": [
    "## Combine models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31941602-4a2f-4170-bbb1-7b1f735465b8",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "Chaining is when models are combined by feeding the output from one model directly into another model as an input. We can chain multiple calls to the same model together or use different models. If we chain two text models together, we can ask the model to perform a task in one call to the API and send it back with an additional instruction.\n",
    "\n",
    "One example is to transcribe an audio file and use perform text capabilities of OpenAI on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3afacd-d63c-4a50-9647-249fef5983e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
