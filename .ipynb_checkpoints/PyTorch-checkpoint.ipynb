{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be5799e-06c7-4139-a978-72788f159ea1",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "PyTorch is a dynamic and powerful tool for building and training machine learning models. It simplifies the process with its fundamental building blocks like tensors and neural networks and offers effective ways to define objectives and improve models using loss functions and optimizers.\n",
    "\n",
    "**Tensors**: multi-dimensional arrays that serve as a foundational data structure in PyTorch.   \n",
    "**Neural Nets**: handled by `torch.nn` module  \n",
    "**Loss Functions**: objective function that needs to be minimized during training  \n",
    "**Optimizers**: algorithms used to minimize the loss function  \n",
    "**Datasets and Dataloaders**: useful tools for working with data at scale easily. \n",
    "**Training Loops**: fundamental steps for training a deep learning model.  \n",
    "\n",
    "\n",
    "[PyTorch quickstart tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75cec5-6a9a-4a42-95fe-ee07ab3f81a4",
   "metadata": {},
   "source": [
    "## PyTorch Tensors\n",
    "Generalized versions of vectors and matrices that can have any number of dimensions (i.e. multi-dimensional arrays). They hold data for processing with operations like addition or multiplication.  \n",
    "[Tensors tutorial](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7d7b9-3344-4ba8-8490-398cf9529573",
   "metadata": {},
   "source": [
    "### Images as PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac7f97f-86e5-450b-8ab7-f0fc8e8ad15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 3-dimensional tensor\n",
    "images = torch.rand((4, 28, 28))\n",
    "\n",
    "# Get the second image\n",
    "second_image = images[1]\n",
    "\n",
    "# Displaying Images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(second_image, cmap='gray')\n",
    "plt.axis('off') # disable axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d2502-af28-4a71-bc67-d0f07caddbfe",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4a3a67-b33b-44a4-86fa-88b3afa0663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 0]])\n",
      "tensor([[2, 1],\n",
      "        [1, 1]])\n",
      "tensor([[3, 2],\n",
      "        [2, 1]])\n",
      "tensor([[5, 3],\n",
      "        [3, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 1], [1, 0]])\n",
    "print(a)\n",
    "print(torch.matrix_power(a, 2))\n",
    "print(torch.matrix_power(a, 3))\n",
    "print(torch.matrix_power(a, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097238b-2fc1-471c-97db-c37ea90062c9",
   "metadata": {},
   "source": [
    "## PyTorch Neural Networks\n",
    "`nn.Module`: Fundamental building block  \n",
    "`nn.Linear`: Fully connected layer  \n",
    "`nn.ReLU`: Non-linear activation function  \n",
    "`forward method`: Defines forward computation  \n",
    "[PyTorch Neural Networks tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6308d3eb-3df2-41ce-87d7-b4e4c5b9706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_layer): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (output_layer): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1286, 0.0329], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 64)\n",
    "        self.output_layer = nn.Linear(64, 2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model = MLP(input_size=10)\n",
    "print(model)\n",
    "\n",
    "model.forward(torch.rand(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed077a-a51e-4d3a-b0af-d5d001da9aed",
   "metadata": {},
   "source": [
    "## PyTorch Loss Functions\n",
    "help in improving the accuracy of a model by measuring errors. They quantify the discrepancy between the predicted output and the actual target values. These functions come in different forms to tackle various problems, like deciding between categories (classification) or predicting values (regression).  \n",
    "Loss functions to be used are selected based on the type of task and the distribution of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad53e2-b256-41d0-8ef6-007acc9ea097",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "suited for classification task. It's particularly useful when the classes are mutually exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e286cf0-f941-4fe1-bff7-f2cb0678be9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Our dataset contains a single image of a dog, where cat = 0 and dog = 1 (corresponding to index 0 and 1)\n",
    "target_tensor = torch.tensor([1])\n",
    "target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c52f5e6c-82b5-46bb-8938-438d0c643cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumitsaurabh\\sumit-saurabh\\Practical DL\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(8.5000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction: Most likely a dog (index 1 is higher)\n",
    "# Note that the values do not need to sum to 1\n",
    "predicted_tensor = torch.tensor([[2.0, 5.0]])\n",
    "loss_value = loss_function(predicted_tensor, target_tensor)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a1cd36-f1c7-4d91-a54a-c6b1d4ecc393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9130)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction: Slightly more likely a cat (index 0 is higher)\n",
    "predicted_tensor = torch.tensor([[1.5, 1.1]])\n",
    "loss_value = loss_function(predicted_tensor, target_tensor)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fb42f-58ed-4ade-90c8-9203bc1d0960",
   "metadata": {},
   "source": [
    "### Mean Squared Error Loss\n",
    "This shows the average of the squares of the differences between predicted and target values. It's often used for predicting continuous values rather than categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a45325-5de0-4821-8ebb-49f6dff6a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000000.0\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Define the predicted and actual values as tensors\n",
    "predicted_tensor = torch.tensor([320000.0])\n",
    "actual_tensor = torch.tensor([300000.0])\n",
    "\n",
    "# Compute the MSE loss\n",
    "loss_value = loss_function(predicted_tensor, actual_tensor)\n",
    "print(loss_value.item()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0a768-3f0e-4a30-af1f-d59194b240b3",
   "metadata": {},
   "source": [
    "> For both measures of loss, `Lower Loss = Better Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa05dea-dfea-4291-8be1-b866ae10a09b",
   "metadata": {},
   "source": [
    "## PyTorch Optimizers\n",
    "help improve how a neural network learns from data by adjusting the model's parameters.\n",
    "\n",
    "Gradients: Directions and amounts by which a function increases most. The parameters can be changed in a direction opposite to the gradient of the loss function in order to reduce the loss.\n",
    "\n",
    "Learning Rate: This hyperparameter specifies how big the steps are when adjusting the neural network's settings during training. Too big, and you might skip over the best setting; too small, and it'll take a very long time to get there.\n",
    "\n",
    "Stochastic Gradient Descent (SGD): This is a fundamental optimizer that updates model parameters based on a subset of data, which can lead to noisy paths towards the optimal solution due to its stochastic nature. To alleviate this techniques such as incoprporating momentum are often introduced.\n",
    "\n",
    "Momentum: A technique used to accelerate the optimizer in the right direction and reduce oscillations in the loss function by accumulating past gradients.\n",
    "\n",
    "Adam Optimizer: Another popular optimizer that often works well out of the box and requires minimal hyperparameter tuning.  \n",
    "[PyTorch Optimization tutorial](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f175abdb-0e3c-499c-a580-7a55d96317f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Assuming 'model' is defined neural network\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# lr=0.01 sets the learning rate to 0.01 for either optimizer.\n",
    "# momentum=0.9 smoothes out updates and can help training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad623a1a-418e-4e1e-abae-ac484222e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cebf3-021e-418b-841f-e5eeddfa2f36",
   "metadata": {},
   "source": [
    "## PyTorch Datasets and Data Loaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a15101d-79b6-4b8d-b7b0-3f9188d2fbe1",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "This serves as a blueprint for defining how data is accessed and transformed. It can handle tasks like accessing and parsing directories and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff1aa97-829d-4a2f-b046-d250b52fed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((3, 4), 12)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Create a toy dataset\n",
    "class NumberProductDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = self.numbers[index]\n",
    "        number2 = self.numbers[index] + 1\n",
    "        return (number1, number2), number1 * number2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers)\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = NumberProductDataset(\n",
    "    data_range=(0, 11)\n",
    ")\n",
    "\n",
    "# Access a data sample\n",
    "data_sample = dataset[3]\n",
    "print(data_sample)\n",
    "# ((3, 4), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5336559-9156-45f6-bcf2-58bedf3c81d1",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "This utility wraps around the dataset object to provide batched, shuffled, and parallelized loading of data. It simplifies the process of iterating over data batches during model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9c6039-5889-45ba-83c4-cbc87c3dd213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 0]), tensor([2, 3, 1])] tensor([2, 6, 0])\n",
      "[tensor([4, 3]), tensor([5, 4])] tensor([20, 12])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = NumberProductDataset(data_range=(0, 5))\n",
    "\n",
    "# Create a DataLoader instance\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "# Iterating over batches\n",
    "for (num_pairs, products) in dataloader:\n",
    "    print(num_pairs, products)\n",
    "# [tensor([4, 3, 1]), tensor([5, 4, 2])] tensor([20, 12, 2])\n",
    "# [tensor([2, 0]), tensor([3, 1])] tensor([6, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25020105-1377-46e4-99b9-a71574ee1362",
   "metadata": {},
   "source": [
    "Batches: Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way.\n",
    "\n",
    "Shuffle: It means mixing up the data so that it's not in the same order every time, which helps the AI learn better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617cec3-7a78-479b-822b-36afa3ac4a11",
   "metadata": {},
   "source": [
    "## PyTorch Training Loops\n",
    "The cycle that a neural network goes through many times to learn from the data by making predictions, checking errors, and improving itself. A PyTorch training loop is an essential part of building a neural network model, which helps us teach the computer how to make predictions or decisions based on data. By using this loop, we gradually improve our model's accuracy through a process of learning from its mistakes and adjusting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f1716-66eb-409c-8e66-b18f02a1f15e",
   "metadata": {},
   "source": [
    "### Create a Number Sum Dataset\n",
    "This dataset has two features—a pair of numbers—and a target value—the sum of those two numbers.\n",
    "\n",
    "Note that this is not actually a good use of deep learning. At the end of our training loop, the model still doesn't know how to add 3 + 7! The idea here is to use a simple example so it's easy to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a41eaf-f1cf-4aaf-b0c3-7e041067b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488b4cd-49b0-4d32-86db-672228b3c3fb",
   "metadata": {},
   "source": [
    "### Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d94332c-614b-44ce-b216-c1cd4ca55318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSumDataset(data_range=(1, 100))\n",
    "\n",
    "for i in range(5):\n",
    "    print(dataset[i])\n",
    "# (tensor([1., 1.]), tensor([2.]))\n",
    "# (tensor([1., 2.]), tensor([3.]))\n",
    "# (tensor([1., 3.]), tensor([4.]))\n",
    "# (tensor([1., 4.]), tensor([5.]))\n",
    "# (tensor([1., 5.]), tensor([6.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b445faa-e045-4a1b-a941-04058422074d",
   "metadata": {},
   "source": [
    "### Define a Simple Model\n",
    "A multi-layer perceptron (MLP) is defined with 128 nodes in the hidden layer and a single output node, using a rectified linear unit (ReLU) as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25658d81-3231-4818-9959-9c43df0e5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a135c0-e60e-42b6-b2e2-482c43b732c1",
   "metadata": {},
   "source": [
    "### Instantiate Components Needed for Training\n",
    "The training loop includes essential components such as the dataset, data loader, model, loss function, and optimizer.\n",
    "\n",
    "Optimizer: Part of the neural network's brain that makes decisions on how to change the network to get better at its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba10878-1f93-4e62-8552-5c8d629ac246",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(0, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cbf64-e478-4a90-a55f-12644b3fcaa3",
   "metadata": {},
   "source": [
    "### Create a Training Loop\n",
    "The loop iterates through a specified number of epochs, processing the entire dataset in batches. For each batch, predictions are made, and the loss is calculated and accumulated.\n",
    "\n",
    "Batches: Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way.\n",
    "\n",
    "Epochs: A complete pass through the entire training dataset. The more epochs, the more the computer goes over the material to learn.\n",
    "\n",
    "Monitoring Progress: After processing all batches, the total loss for the epoch is printed to monitor training progress. The expectation is that the loss decreases over time, indicating that the model is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d63eb3-b741-4a5e-a83a-e4e4ee8017f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Losses = 211077.64546\n",
      "Epoch 1: Sum of Batch Losses = 3846.18512\n",
      "Epoch 2: Sum of Batch Losses = 527.26615\n",
      "Epoch 3: Sum of Batch Losses = 26.77519\n",
      "Epoch 4: Sum of Batch Losses = 4.76441\n",
      "Epoch 5: Sum of Batch Losses = 3.58256\n",
      "Epoch 6: Sum of Batch Losses = 3.13230\n",
      "Epoch 7: Sum of Batch Losses = 2.42945\n",
      "Epoch 8: Sum of Batch Losses = 1.65126\n",
      "Epoch 9: Sum of Batch Losses = 1.51090\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0.0\n",
    "    for number_pairs, sums in dataloader:  # Iterate over the batches\n",
    "        predictions = model(number_pairs)  # Compute the model output\n",
    "        loss = loss_function(predictions, sums)  # Compute the loss\n",
    "        loss.backward()  # Perform backpropagation\n",
    "        optimizer.step()  # Update the parameters\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        total_loss += loss.item()  # Add the loss for all batches\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(\"Epoch {}: Sum of Batch Losses = {:.5f}\".format(epoch, total_loss))\n",
    "    # Epoch 0: Sum of Batch Losses = 118.82360\n",
    "    # Epoch 1: Sum of Batch Losses = 39.75702\n",
    "    # Epoch 2: Sum of Batch Losses = 2.16352\n",
    "    # Epoch 3: Sum of Batch Losses = 0.25178\n",
    "    # Epoch 4: Sum of Batch Losses = 0.22843\n",
    "    # Epoch 5: Sum of Batch Losses = 0.19182\n",
    "    # Epoch 6: Sum of Batch Losses = 0.15507\n",
    "    # Epoch 7: Sum of Batch Losses = 0.07789\n",
    "    # Epoch 8: Sum of Batch Losses = 0.06329\n",
    "    # Epoch 9: Sum of Batch Losses = 0.04936"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7eb4dc-d935-46be-ad08-7628b0914d9e",
   "metadata": {},
   "source": [
    "### Try the Model Out\n",
    "Model Testing: The video concludes with a demonstration of testing the model with specific inputs to see how well it predicts the sum of two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be53878-6c81-4eb4-a1a8-b7344b425843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.2475], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model on 3 + 7\n",
    "model(torch.tensor([3.0, 7.0]))\n",
    "# tensor([10.1067], grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee72ed-73a6-4ee8-aae4-6e694d1dae81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Practical DL",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
