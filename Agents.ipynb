{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fc24d0-75fd-44a3-b268-ec802a8074ca",
   "metadata": {},
   "source": [
    "# LLM Agent\n",
    "involve LLM applications that can execute complex tasks through the use of an architecture that combines LLMs with key modules like planning and memory. When building LLM agents, an LLM serves as the main controller or \"brain\" that controls a flow of operations needed to complete a task or user request. The LLM agent may require key modules such as planning, memory, and tool usage.\n",
    "\n",
    "Generally, an LLM agent framework can consist of the following core components:\n",
    "\n",
    "User Request - a user question or request  \n",
    "Agent/Brain - the agent core acting as coordinator  \n",
    "Planning - assists the agent in planning future actions  \n",
    "Memory - manages the agent's past behaviors\n",
    "\n",
    "- a system that can use an LLM to reason through a problem, create a plan to solve the problem, and execute the plan with the help of a set of tools. \n",
    "\n",
    "In short, agents are a system with complex reasoning capabilities, memory, and the means to execute tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc5772-d5e8-41a8-9599-77073ee48677",
   "metadata": {},
   "source": [
    "## Agent\n",
    "A large language model (LLM) with general-purpose capabilities serves as the main brain, agent module, or coordinator of the system. This component will be activated using a prompt template that entails important details about how the agent will operate, and the tools it will have access to (along with tool details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b9399-a03d-4c67-9ec0-445042dff124",
   "metadata": {},
   "source": [
    "## Planning\n",
    "At the core of any effective AI agent is its planning capability, powered by large language models (LLMs). Modern LLMs enable several crucial planning functions:\n",
    "\n",
    "- Task decomposition through chain-of-thought reasoning\n",
    "- Self-reflection on past actions and information\n",
    "- Adaptive learning to improve future decisions\n",
    "- Critical analysis of current progress\n",
    "While current LLM planning capabilities aren't perfect, they're essential for task completion. Without robust planning abilities, an agent cannot effectively automate complex tasks, which defeats its primary purpose.\n",
    "### Planning without Feedback\n",
    "The planning module helps to break down the necessary steps or subtasks the agent will solve individually to answer the user request. This step is important to enable the agent to reason better about the problem and reliably find a solution. The planning module will leverage an LLM to decompose a detailed plan which will include subtasks to help address the user question. Popular techniques for task decomposition include Chain of Thought and Tree of Thoughts which can be categorized as single-path reasoning and multi-path reasoning, respectively.\n",
    "\n",
    "### Planning with Feedback\n",
    "The planning modules above don't involve any feedback which makes it challenging to achieve long-horizon planning to solve complex tasks. To address this challenge, you can leverage a mechanism that enables the model to iteratively reflect and refine the execution plan based on past actions and observations. The goal is to correct and improve on past mistakes which helps to improve the quality of final results. This is particularly important in complex real-world environments and tasks where trial and error are key to completing tasks. Two popular methods for this reflection or critic mechanism include ReAct and Reflexion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef4d68-9169-45a4-a27d-41d5ed335a69",
   "metadata": {},
   "source": [
    "## Memory\n",
    "The memory module helps to store the agent's internal logs including past thoughts, actions, and observations from the environment, including all interactions between agent and user. There are two main memory types that have been reported in the LLM agent literature:\n",
    "\n",
    "- Short-term (working) memory - includes context information about the agent's current situations; this is typically realized by in-context learning which means it is short and finite due to context window constraints.\n",
    "    - Functions as a buffer for immediate context\n",
    "    - Enables in-context learning\n",
    "    - Sufficient for most task completions\n",
    "    - Helps maintain continuity during task iteration\n",
    "- Long-term memory - includes the agent's past behaviors and thoughts that need to be retained and recalled over an extended period of time; this often leverages an external vector store accessible through fast and scalable retrieval to provide relevant information for the agent as needed.\n",
    "Hybrid memory integrates both short-term memory and long-term memory to improve an agent's ability for long-range reasoning and accumulation of experiences.\n",
    "    - Implemented through external vector stores\n",
    "    - Enables fast retrieval of historical information\n",
    "    - Valuable for future task completion\n",
    "    - Less commonly implemented but potentially crucial for future developments\n",
    "\n",
    "There are also different memory formats to consider when building agents. Representative memory formats include natural language, embeddings, databases, and structured lists, among others. These can also be combined such as in Ghost in the Minecraft (GITM) that utilizes a key-value structure where the keys are represented by natural language and values are represented by embedding vectors.\n",
    "\n",
    "Both the planning and memory modules allow the agent to operate in a dynamic environment and enable it to effectively recall past behaviors and plan future actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593ae25-85cf-49e2-85cd-69bdd12899bd",
   "metadata": {},
   "source": [
    "## Tools\n",
    "Tools correspond to a set of tool/s that enables the LLM agent to interact with external environments such as Wikipedia Search API, Code Interpreter, and Math Engine. Tools could also include databases, knowledge bases, and external models. When the agent interacts with external tools it executes tasks via workflows that assist the agent to obtain observations or necessary information to complete subtasks and satisfy the user request.\n",
    "\n",
    "Tools are leveraged in different ways by LLMs:\n",
    "\n",
    "[MKRL](https://arxiv.org/abs/2205.00445) is a framework that combines LLMs with expert modules that are either LLMs or symbolic (calculator or weather API).  \n",
    "[Toolformer](https://arxiv.org/abs/2302.04761) fine-tune LLMs to use external tool APIs.  \n",
    "[Function Calling](https://www.promptingguide.ai/applications/function_calling) - augments LLMs with tool use capability which involves defining a set of tool APIs and providing it to the model as part of a request.  \n",
    "[HuggingGPT](https://arxiv.org/abs/2303.17580 )- an LLM-powered agent that leverages LLMs as a task planner to connect various existing AI models (based on descriptions) to solve AI tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19056ce7-84d6-4c11-a4eb-bc72f4f6d4d7",
   "metadata": {},
   "source": [
    "## LLM Agent Tools\n",
    "Below are notable examples of tools and frameworks that are used to build LLM agents:\n",
    "\n",
    "LangChain: a framework for developing applications and agents powered by language models.\n",
    "AutoGPT: provides tools to build AI agents.\n",
    "Langroid: Simplifies building LLM applications with Multi-Agent Programming: agents as first-class citizens, collaborating on tasks via messages.\n",
    "AutoGen: a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks.\n",
    "OpenAgents: an open platform for using and hosting language agents in the wild.\n",
    "LlamaIndex - a framework for connecting custom data sources to large language models.\n",
    "GPT Engineer: automate code generation to complete development tasks.\n",
    "DemoGPT: autonomous AI agent to create interactive Streamlit apps.\n",
    "GPT Researcher: an autonomous agent designed for comprehensive online research on a variety of tasks.\n",
    "AgentVerse: designed to facilitate the deployment of multiple LLM-based agents in various applications.\n",
    "Agents: an open-source library/framework for building autonomous language agents. The library supports features including long-short term memory, tool usage, web navigation, multi-agent communication, and brand new features including human-agent interaction and symbolic control.\n",
    "BMTools: extends language models using tools and serves as a platform for the community to build and share tools.\n",
    "crewAI: AI agent framework reimagined for engineers, offering powerful capabilities with simplicity to build agents and automations.\n",
    "Phidata: a toolkit for building AI Assistants using function calling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea11e1-3a94-473b-8535-9b66ef5e88f3",
   "metadata": {},
   "source": [
    "## Common Use Cases for AI Agents\n",
    "Here is a non-exhaustive list of common use cases where agents are being applied in the industry:\n",
    "\n",
    "Recommendation systems: Personalizing suggestions for products, services, or content.  \n",
    "Customer support systems: Handling inquiries, resolving issues, and providing assistance.  \n",
    "Research: Conducting in-depth investigations across various domains, such as legal, finance, and health.  \n",
    "E-commerce applications: Facilitating online shopping experiences, managing orders, and providing personalized recommendations.  \n",
    "Booking: Assisting with travel arrangements and event planning.  \n",
    "Reporting: Analyzing vast amounts of data and generating comprehensive reports.  \n",
    "Financial analysis: Analyzing market trends, assess financial data, and generate reports with unprecedented speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70377cdd-7317-4f8b-9c75-41d14a88dd4b",
   "metadata": {},
   "source": [
    "## LLM Agent Evaluation\n",
    "Similar to evaluating LLM themselves, evaluating LLM agents is a challenging task. According to Wang et al., (2023), common evaluation methods include:\n",
    "\n",
    "Human Annotation: Includes human evaluators that directly score LLM results across different aspects that matter in the application such as honesty, helpfulness, engagement, unbiasedness, and more.  \n",
    "Turing Test: Human evaluators are asked to compare results from real humans and agents where indistinguishable results mean that agents can achieve human-like performance.  \n",
    "Metrics: These are carefully designed metrics that reflect the quality of the agents. Notable metrics include task success metrics, human similarity metrics, and efficiency metrics.  \n",
    "Protocols: Corresponds to common evaluation protocols that determine how the metrics are used. Examples include real-world simulation, social evaluation, multi-task evaluation, and software testing.  \n",
    "Benchmarks: Several benchmarks have been designed to evaluate LLM agents. Notable examples include ALFWorld, IGLU, Tachikuma, AgentBench, SocKET, AgentSims, ToolBench, WebShop, Mobile-Env, WebArena, GentBench, RocoBench, EmotionBench, PEB, ClemBench, and E2E."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c79b8-d0d8-493d-856d-e6fb47f09d03",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "LLM agents are still in their infancy so there are many challenges and limitations that remain when building them:\n",
    "\n",
    "- Role-playing capability: LLM-based agents typically need to adapt a role to effectively complete tasks in a domain. For roles that the LLM doesn't characterize well, it's possible to fine-tune the LLM on data that represent uncommon roles or psychology characters.  \n",
    "- Long-term planning and finite context length: planning over a lengthy history remains a challenge that could lead to errors that the agent may not recover from. LLMs are also limited in context length they can support which could lead to constraints that limit the capabilities of the agent such as leveraging short-term memory.  \n",
    "- Generalized human alignment: it's also challenging to align agents with diverse human values which is also common with standard LLMs. A potential solution involves the potential to realign the LLM by designing advanced prompting strategies.  \n",
    "Prompt robustness and reliability: an LLM agent can involve several prompts designed to power the different modules like memory and planning. It's common to encounter reliability issues in LLMs with even the slightest changes to prompts. LLM agents involve an entire prompt framework which makes it more prone to robustness issues. The potential solutions include crafting prompt elements through trial and error, automatically optimizing/tuning prompts, or automatically generating prompts using GPT. Another common issue with LLMs is hallucination which is also prevalent with LLM agents. These agents rely on natural language to interface with external components that could be introducing conflicting information leading to hallucination and factuality issues.  \n",
    "- Knowledge boundary: similar to knowledge mismatch issues that could lead to hallucination or factuality issues, it's challenging to control the knowledge scope of LLMs which can significantly impact the effectiveness of simulations. Concretely, an LLM's internal knowledge could introduce biases or utilize user-unknown knowledge that could affect the agent's behavior when operating in specific environments.  \n",
    "- Efficiency: LLM agents involve a significant amount of requests that are handled by the LLM which could affect the efficiency of agent actions because it would depend heavily on the LLM inference speed. Cost is also a concern when deploying multiple agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6260aa-a3a0-4110-a917-62643fcaa50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
